2020-10-02 14:52:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 13, in parse
    print(labels.text)
AttributeError: text
2020-10-02 14:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 13, in parse
    print(labels.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2020-10-02 15:02:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:02:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:02:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:03:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 25, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:04:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:34:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:35:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:35:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:36:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:36:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:37:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:39:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:39:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:39:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:40:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 25, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:42:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:43:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 25, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:52:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:52:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:52:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:53:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:53:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:53:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 16:00:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:00:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:00:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:01:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:01:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:01:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:02:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:02:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:02:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:06:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 48, in parse_sun_info
    item['reponsetime'] = li.css('[class="state4"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','').replace('"','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 16:06:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 48, in parse_sun_info
    item['reponsetime'] = li.css('[class="state4"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','').replace('"','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 16:06:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 48, in parse_sun_info
    item['reponsetime'] = li.css('[class="state4"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','').replace('"','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 16:07:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:07:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 48, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:07:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:08:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:08:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:08:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:08:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:08:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:08:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:09:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 57, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:09:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:09:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 57, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:10:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:10:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 57, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':{'a':1},'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:10:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 57, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':{'a':1},'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:10:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:10:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:10:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:11:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:11:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:11:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:12:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 59, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:12:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:12:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 59, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:13:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:13:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:13:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:14:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:14:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:14:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:14:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:15:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:15:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:15:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:15:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:15:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:15:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:20:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:20:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:20:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:21:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:21:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:21:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:23:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:23:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:23:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:28:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:28:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:28:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:32:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:32:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:32:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:32:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 51, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:32:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:32:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:33:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 52, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:33:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:33:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 52, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:34:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 52, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:34:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:34:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:37:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 52, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:38:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 53, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:39:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:39:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:39:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 53, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:40:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:40:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 55, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:40:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:41:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 55, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t',''))
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:42:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:49:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:54:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:54:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:54:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:55:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 41, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:55:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 41, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:55:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 41, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:55:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:57:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:57:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:57:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 17:18:48 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://wz.sun0769.com/robots.txt>: Unsupported scheme: b''
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\python\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\python\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 55, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 76, in download_request
    return handler.download_request(request, spider)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 88, in download_request
    return agent.download_request(request)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 354, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 268, in request
    endpoint=self._getEndpoint(self._proxyURI),
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1721, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1599, in endpointForURI
    raise SchemeNotSupported("Unsupported scheme: %r" % (uri.scheme,))
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''
2020-10-02 17:18:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://wz.sun0769.com/political/index/politicsNewest>
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\python\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\python\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 55, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 76, in download_request
    return handler.download_request(request, spider)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 88, in download_request
    return agent.download_request(request)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 354, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 268, in request
    endpoint=self._getEndpoint(self._proxyURI),
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1721, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1599, in endpointForURI
    raise SchemeNotSupported("Unsupported scheme: %r" % (uri.scheme,))
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''
2020-10-02 17:24:11 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://wz.sun0769.com/robots.txt>: Unsupported scheme: b''
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\python\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\python\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 55, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 76, in download_request
    return handler.download_request(request, spider)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 88, in download_request
    return agent.download_request(request)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 354, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 268, in request
    endpoint=self._getEndpoint(self._proxyURI),
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1721, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1599, in endpointForURI
    raise SchemeNotSupported("Unsupported scheme: %r" % (uri.scheme,))
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''
2020-10-02 17:24:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://wz.sun0769.com/political/index/politicsNewest>
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\python\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\python\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 55, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 76, in download_request
    return handler.download_request(request, spider)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 88, in download_request
    return agent.download_request(request)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 354, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 268, in request
    endpoint=self._getEndpoint(self._proxyURI),
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1721, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1599, in endpointForURI
    raise SchemeNotSupported("Unsupported scheme: %r" % (uri.scheme,))
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 16:34:52',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474994'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 15:29:44',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474992'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 12:34:47',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474989'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 10:31:51',
 'reponsetime': '3466',
 'status': '',
 'title': '1',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474975'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 10:25:18',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474974'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 10:19:52',
 'reponsetime': '3466',
 'status': '',
 'title': '101',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474973'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 10:17:53',
 'reponsetime': '3466',
 'status': '',
 'title': '6',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474972'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 09:57:26',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474971'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 09:00:47',
 'reponsetime': '332331',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474969'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 23:17:37',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474968'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 21:56:27',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474963'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 20:53:11',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474960'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 20:41:11',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474959'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 20:35:39',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474958'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 20:16:48',
 'reponsetime': '332317',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474957'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 14:22:56',
 'reponsetime': '',
 'status': '',
 'title': '!',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474991'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 11:30:01',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474985'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-02 10:46:42',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474976'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 22:17:21',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474964'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 21:53:28',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474962'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 05:23:40',
 'reponsetime': '',
 'status': '',
 'title': '551',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474924'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-30 14:48:27',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474892'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-30 11:23:09',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474863'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-30 11:16:50',
 'reponsetime': '',
 'status': '',
 'title': '?',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474861'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-30 11:15:54',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474860'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-30 08:55:19',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474836'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-29 16:55:55',
 'reponsetime': '',
 'status': '',
 'title': '6+2',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474800'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-29 15:38:00',
 'reponsetime': '',
 'status': '',
 'title': '9266+2',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474789'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-29 13:22:51',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474777'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-29 02:23:22',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474732'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-30 15:59:45',
 'reponsetime': '3366',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474897'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-24 22:20:01',
 'reponsetime': '32225',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474328'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-23 11:52:42',
 'reponsetime': '311721',
 'status': '',
 'title': '  1.7KM',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474152'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-22 16:19:05',
 'reponsetime': '71546',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474068'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-22 11:59:14',
 'reponsetime': '2566',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474029'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-21 18:03:02',
 'reponsetime': '2620',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473953'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-19 23:11:49',
 'reponsetime': '241716',
 'status': '',
 'title': '4',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473787'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-18 14:18:54',
 'reponsetime': '2188',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473646'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-18 11:07:23',
 'reponsetime': '28177',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473610'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-17 15:55:51',
 'reponsetime': '2066',
 'status': '',
 'title': 'S358',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473530'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-16 22:25:48',
 'reponsetime': '212121',
 'status': '',
 'title': '4',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473440'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-16 14:49:14',
 'reponsetime': '1966',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473375'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-15 10:20:03',
 'reponsetime': '261640',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473149'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-13 08:14:48',
 'reponsetime': '4611',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=472882'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-11 12:43:19',
 'reponsetime': '1554',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=472692'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 19:50:55',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474956'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 18:15:54',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474954'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 18:01:56',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474953'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 17:16:58',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474952'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 15:25:00',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474950'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 15:21:11',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474949'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 14:31:13',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474948'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 13:10:38',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474943'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 12:53:43',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474942'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 12:28:28',
 'reponsetime': '332321',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474937'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 12:22:15',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474936'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 11:07:07',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474931'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 10:15:24',
 'reponsetime': '331734',
 'status': '',
 'title': '2019',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474925'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 05:11:36',
 'reponsetime': '3466',
 'status': '',
 'title': '551',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474923'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-10-01 01:14:25',
 'reponsetime': '3466',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474922'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [sunpolicy.spiders.sun] WARNING: ,3
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-28 20:05:37',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474714'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-28 16:46:53',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474698'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-28 16:18:35',
 'reponsetime': '',
 'status': '',
 'title': '9',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474694'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-28 14:28:10',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474670'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-28 10:49:58',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474614'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-28 09:12:03',
 'reponsetime': '',
 'status': '',
 'title': '9266+2',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474600'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-28 00:05:10',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474586'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-27 14:44:51',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474543'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-27 11:41:30',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474528'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-27 09:43:06',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474516'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-26 21:01:36',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474501'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-26 20:22:54',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474498'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-26 18:56:47',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474494'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-26 13:14:47',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474482'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'querytime': '2020-09-26 09:30:02',
 'reponsetime': '',
 'status': '',
 'title': 'ETC',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474459'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [sunpolicy.spiders.sun] WARNING: ,3
2020-10-02 17:54:05 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 17:54:09 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 18:42:15 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 18:42:46 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 18:42:49 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 18:42:52 [sunpolicy.spiders.sun] WARNING: ,2
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '551',
 'img_url_list': [],
 'querytime': '2020-10-01 05:23:40',
 'reponsetime': '',
 'status': '',
 'title': '551',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474924'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/0930/mark_1601448485547494.jpg'],
 'querytime': '2020-09-30 14:48:27',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474892'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-30 11:23:09',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474863'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '',
 'img_url_list': [],
 'querytime': '2020-10-02 10:46:42',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474976'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/1002/mark_1601609394806254_750x.png'],
 'querytime': '2020-10-02 11:30:01',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474985'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [sunpolicy.spiders.sun] WARNING: ,3
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-29 02:23:22',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474732'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '8012080.80',
 'img_url_list': [],
 'querytime': '2020-10-01 22:17:21',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474964'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '261383',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/1002/mark_1601619705442706.jpg'],
 'querytime': '2020-10-02 14:22:56',
 'reponsetime': '',
 'status': '',
 'title': '!',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474991'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '',
 'img_url_list': [],
 'querytime': '2020-09-29 13:22:51',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474777'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '',
 'img_url_list': [],
 'querytime': '2020-10-01 21:53:28',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474962'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': None,
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/0930/mark_1601435809318871_750x.jpg'],
 'querytime': '2020-09-30 11:16:50',
 'reponsetime': '',
 'status': '',
 'title': '?',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474861'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-29 15:38:00',
 'reponsetime': '',
 'status': '',
 'title': '9266+2',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474789'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '9266+2',
 'img_url_list': [],
 'querytime': '2020-09-30 08:55:19',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474836'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-30 11:15:54',
 'reponsetime': '',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474860'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/1001/mark_1601556071314172_750x.jpg'],
 'querytime': '2020-10-01 20:41:11',
 'reponsetime': '34517',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474959'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-29 16:55:55',
 'reponsetime': '',
 'status': '',
 'title': '6+2',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474800'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '',
 'content': '88',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/1001/mark_1601555728753535_750x.png',
                  'http://ugcuploadzdg.sun0769.com/1/2020/1001/mark_1601555734910488_750x.png'],
 'querytime': '2020-10-01 20:35:39',
 'reponsetime': '34517',
 'status': '',
 'title': '',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474958'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [sunpolicy.spiders.sun] WARNING: ,3
